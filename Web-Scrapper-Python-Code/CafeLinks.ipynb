{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as rq\n",
    "import re\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from IPython.core.display import clear_output\n",
    "\n",
    "##depends on which website you going\n",
    "page = rq.get(\"https://www.burpple.com/search/sg?utf8=%E2%9C%93&sort=trending&category_id=5&area_id=&distance_to=0.0&price_from=0&price_to=&q=tanjong+pagar+cafe&ll=&commit=Apply\")\n",
    "#download the website, to know if succcessful, write 'page' then run\n",
    "#the status should come out 200\n",
    "\n",
    "# I used Chrome; you can use whichever browser you like.\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Tell Selenium to get the URL you're interested in.\n",
    "driver.get(\"https://www.burpple.com/search/sg?utf8=%E2%9C%93&sort=trending&category_id=5&area_id=&distance_to=0.0&price_from=0&price_to=&q=tanjong+pagar+cafe&ll=&commit=Apply\")\n",
    "\n",
    "\n",
    "lenOfPage = driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;\")\n",
    "match=False\n",
    "while(match==False):\n",
    "                lastCount = lenOfPage\n",
    "                time.sleep(3)\n",
    "                lenOfPage = driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;\")\n",
    "                time.sleep(6)\n",
    "                if lastCount==lenOfPage:\n",
    "                    match=True\n",
    "\n",
    "#Now that the page is fully scrolled, grab the source code.\n",
    "source_data = driver.page_source\n",
    "\n",
    "#Throw the source into BeautifulSoup and start parsing\n",
    "soup = bs(source_data,'lxml')\n",
    "\n",
    "\n",
    "### xxxxx \n",
    "### below codes can just add onto 'final burpple individual cafes' code , since the scrolling of the page is the same\n",
    "### the above codes is irrelevant if you already parse the website \n",
    "\n",
    "container = soup.find_all(\"div\",{\"class\": \"searchVenue-header card-item card-item--header\"})\n",
    "    \n",
    "\n",
    "links = []\n",
    "price = []\n",
    "food = []\n",
    "review = []\n",
    "names = []\n",
    "\n",
    "for item in container:\n",
    "        \n",
    "    review_elem = item.find(\"span\",{\"class\": \"searchVenue-header-reviews\"}).text\n",
    "    \n",
    "#you can only get .text from find()\n",
    "#if you want to get from findall() you need to specify the index eg. [0]\n",
    "\n",
    "   #must put .text if not the review_elem will be the html code instead of specific text you want\n",
    "    reviewstrip = review_elem.strip('Reviews\": ')\n",
    "    intreview = int(reviewstrip)\n",
    "        \n",
    "        \n",
    "    if (intreview > 4 ):\n",
    "    #in case some cafes dont have this information\n",
    "        link_elem = item.find('a', attrs={'href': re.compile(\"^/\")})\n",
    "    #re.compile(\"^/\") is to match the url starting with /\n",
    "        links.append(link_elem.get('href'))\n",
    "        \n",
    "        names_elem = item.find(\"span\",{\"class\": \"searchVenue-header-name-name headingMedium\"}).text\n",
    "        names.append(names_elem)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlink = pd.DataFrame({\n",
    "        \"Cafe_Name \": names,\n",
    "        \"Links\" : links\n",
    "    \n",
    "    })\n",
    "\n",
    "testlink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = pd.ExcelWriter('CompiledCafeLinks.xlsx', options={'encoding':'utf-8'})\n",
    "testlink.to_excel(ex, 'Data', index=False)\n",
    "ex.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save time for subsequent scripts, so dont need parse the burpple tanjong pagar cafes again to find the links\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "xl_workbook = pd.ExcelFile('C:/Users/Mei Xuan/Downloads/CompiledCafeLinks.xlsx')  # Load the excel workbook\n",
    "df = xl_workbook.parse(\"Data\")  # Parse the sheet into a dataframe\n",
    "aList = df['Links'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test if the link will work\n",
    "print(\"Test Next Page URL: {}\".format('https://www.burpple.com'+aList[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
